# -*- coding: utf-8 -*-
"""Indonesian Abusive and Hate Speech Twitter Text.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BEWujVzin1NUfCwiUc3CiOVg534ORZU1
"""

"""
importing library needed
"""

import pandas as pd
import re

from text_cleaning_helper import normalize_alay

"""IMPORTING DATA DAN DATA EXPLORATION

A. DATA ABUSIVE. CSV
"""

1. #membaca dataset 
df_abusive = pd.read_csv ("/content/abusive.csv")
df_abusive.head ()

print (df_abusive.info())
print ('\n')
print (df_abusive.describe())
print (df_abusive.isnull().sum())

print (df_abusive.info())
print ('\n')
print (df_abusive.describe())
print (df_abusive.isnull().sum())

"""B. DATA NEW_KAMUSALAY.CSV"""

df_alay = pd.read_csv("//content/new_kamusalay.csv", encoding = 'iso - 8859 - 1')
df_alay.head ()

print(df_alay.info())
print ('\n')
print (df_alay.describe())
print ('\n')
print (df_alay.isnull(). sum ())

"""C. DATA DATA.CSV"""

df_data = pd.read_csv ("/content/data.csv", encoding = 'iso - 8859 - 1')
df_data.head ()

print (df_data.info())
print ('\n')
print (df_data.describe())

df_data.isnull().sum()

"""DATA MANIPULATION"""

# shape of column
range (df_data.shape[0])

df_data_filtered = df_data.drop ('Tweet', axis = 1, inplace = False)
df_data_filtered.head()

df_data ['Classification'] = "Dummy"
for i in range (df_data_filtered.shape [0]):
    if 1 in df_data_filtered.loc [i]. tolist ():
      df_data['Classification'][i] = "yes"
    else: 
      df_data ['Classification'][i] = "no"

df_data.head ()

"""DATA VISUALIZATION"""

df_data ['Classification'].value_counts()

import matplotlib.pyplot as plt

df_data ['Classification'].value_counts().plot (kind = 'pie')
figsize = (6,7),
autopct = '%1.1f%%', #add in percentages
startangle = 90,  #start angle 90Â° derajat
shadow = True, #add Shadow
plt.show 

plt.legend (['yes','no'])
plt.title ('Classification Data on Hate Speech in Twitter Data Set')
plt.axis ('equal') #Sets the pie chart to look like a circle
ax = plt.axes ()

plt.show

"""Berdasarkan Visualisasi Data diatas bisa kita lihat tweet yang mengandung kata-kata Hate Speech jauh lebih besar dari pada yang tweet yang "tidak" mengandung kata-kata Hate Speech

DATA CLEANSING
"""

df_data.head (10)

Tweets = df_data ['Tweet'].tolist ()
print (Tweets)

alay_dict = df_alay. rename (columns = {0: 'original',
                                          1: 'replacement'})

alay_dict

print ([df_data ['Tweet'][0].split () ])

"""PREPROCESS DATA CLEANING"""

import re
import pandas as pd
import sqlite3


def lowercase(text):
    return text.lower()

def remove_unnecessary_char(text):
    text = re.sub('\n',' ', text)
    text = re.sub('rt',' ', text)
    text = re.sub('user',' ', text)
    text = re.sub('((www\.[^\s]+)|(https?://[^\s]+)|(http?://[^\s]+))',' ',text)
    text = re.sub('  +',' ', text)
    return text

def remove_nonaplhanumeric(text):
    text = re.sub('[^0-9a-zA-Z]+', ' ', text)
    text = re.sub('  +',' ', text) 
    return text

# Untuk Proses Cleaning Data
def preprocess(text):
    text = lowercase(text) # 1
    text = remove_unnecessary_char(text) # 2
    text = remove_nonaplhanumeric(text) # 3
    text = normalize_alay(text) # 4
    return text


# Untuk Proses Text
def process_text(input_text):
    try: 
        output_text = preprocess(input_text)
        return output_text
    except:
        print("Text is unreadable")